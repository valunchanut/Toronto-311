{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f99b7a",
   "metadata": {},
   "source": [
    "# 01 · Data Extraction & Transformation — Toronto 311 (Customer-Initiated)\n",
    "Auto-discover yearly resources via CKAN, pull 2021–2025 YTD, clean, and export tidy CSVs.\n",
    "**Defaults:** exclude `Canceled` statuses for demand analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a710694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: https://www.toronto.ca/data/311/opendata/servicerequest/SR2021.zip\n",
      "Reading: https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/2e54bc0e-4399-4076-b717-351df5918ae7/resource/f00a3313-f074-463e-89a7-26563084fbef/download/sr2022.zip\n",
      "Reading: https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/2e54bc0e-4399-4076-b717-351df5918ae7/resource/079766f3-815d-4257-8731-5ff6b0c84c13/download/sr2023.zip\n",
      "Reading: https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/2e54bc0e-4399-4076-b717-351df5918ae7/resource/f46b640d-d465-4f8b-9db5-5000a08295cd/download/sr2024.zip\n",
      "Reading: https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/2e54bc0e-4399-4076-b717-351df5918ae7/resource/f3db05ab-2588-4159-89f7-56c74d1d8201/download/sr2025.zip\n",
      "Wrote:\n",
      " - 311_counts_year_type_2021_2025.csv\n",
      " - 311_top_types_by_year_2021_2025.csv\n",
      " - 311_daily_totals_2021_2025.csv\n",
      " - 311_counts_year_type_division_ward_2021_2025.csv (may be empty if cols absent)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URLS = [\n",
    "    \"https://www.toronto.ca/data/311/opendata/servicerequest/SR2021.zip\",\n",
    "    \"https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/2e54bc0e-4399-4076-b717-351df5918ae7/resource/f00a3313-f074-463e-89a7-26563084fbef/download/sr2022.zip\",\n",
    "    \"https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/2e54bc0e-4399-4076-b717-351df5918ae7/resource/079766f3-815d-4257-8731-5ff6b0c84c13/download/sr2023.zip\",\n",
    "    \"https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/2e54bc0e-4399-4076-b717-351df5918ae7/resource/f46b640d-d465-4f8b-9db5-5000a08295cd/download/sr2024.zip\",\n",
    "    \"https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/2e54bc0e-4399-4076-b717-351df5918ae7/resource/f3db05ab-2588-4159-89f7-56c74d1d8201/download/sr2025.zip\"\n",
    "]\n",
    "\n",
    "# Some years use slightly different column labels — handle that here\n",
    "DATE_CANDS   = [\"Service Request Creation Date and Time\", \"Creation Date\", \"SR Creation Date and Time\"]\n",
    "TYPE_CANDS   = [\"Original Service Request Type\", \"Service Request Type\", \"Original Problem Type\"]\n",
    "STATUS_CANDS = [\"Service Request Status\", \"Status\"]\n",
    "DIV_CANDS    = [\"Service Request Division\", \"Division\"]\n",
    "WARD_CANDS   = [\"Service Request Ward\", \"Ward\"]\n",
    "\n",
    "CHUNK = 100_000  # adjust if you like\n",
    "\n",
    "def pick_col(cols, candidates):\n",
    "    cset = {c.lower().strip(): c for c in cols}\n",
    "    for cand in candidates:\n",
    "        k = cand.lower().strip()\n",
    "        if k in cset:\n",
    "            return cset[k]\n",
    "    return None\n",
    "\n",
    "def stream_zip_one(url: str):\n",
    "    \"\"\"\n",
    "    Reads a single-CSV ZIP directly from URL using pandas (compression='zip'), in chunks.\n",
    "    Returns three small DataFrames:\n",
    "      - counts_y_t         (year x type)\n",
    "      - counts_y_t_d_w     (year x type x division x ward)  [empty if cols missing]\n",
    "      - daily              (day totals)\n",
    "    \"\"\"\n",
    "    agg_year_type = defaultdict(int)\n",
    "    agg_year_type_div_ward = defaultdict(int)\n",
    "    agg_daily = defaultdict(int)\n",
    "\n",
    "    # First tiny peek to detect actual column names quickly\n",
    "    head = pd.read_csv(\n",
    "        url,\n",
    "        compression=\"zip\",\n",
    "        nrows=5,\n",
    "        low_memory=False,\n",
    "        on_bad_lines=\"skip\",\n",
    "    )\n",
    "    # Normalize stripped/lowercase to find canonical names\n",
    "    head = head.rename(columns={c: c.strip() for c in head.columns})\n",
    "    date_col   = pick_col(head.columns, DATE_CANDS)\n",
    "    type_col   = pick_col(head.columns, TYPE_CANDS)\n",
    "    status_col = pick_col(head.columns, STATUS_CANDS)\n",
    "    div_col    = pick_col(head.columns, DIV_CANDS)\n",
    "    ward_col   = pick_col(head.columns, WARD_CANDS)\n",
    "\n",
    "    if not date_col or not type_col:\n",
    "        raise ValueError(f\"Required columns not found in {url}\\nFound: {list(head.columns)}\")\n",
    "\n",
    "    usecols = [date_col, type_col]\n",
    "    if status_col: usecols.append(status_col)\n",
    "    if div_col:    usecols.append(div_col)\n",
    "    if ward_col:   usecols.append(ward_col)\n",
    "\n",
    "    it = pd.read_csv(\n",
    "        url,\n",
    "        compression=\"zip\",\n",
    "        usecols=lambda c: (c.strip() in usecols) if isinstance(c, str) else False,\n",
    "        parse_dates=[date_col],\n",
    "        on_bad_lines=\"skip\",\n",
    "        low_memory=False,\n",
    "        chunksize=CHUNK,\n",
    "        encoding=\"cp1252\",\n",
    "    )\n",
    "\n",
    "    for df in it:\n",
    "        df = df.rename(columns={c: c.strip() for c in df.columns})\n",
    "\n",
    "        # Keep canceled rows as long as a type exists\n",
    "        df = df.dropna(subset=[date_col, type_col])\n",
    "        df[type_col] = df[type_col].astype(str).str.strip()\n",
    "        df = df[df[type_col] != \"\"]  # drops empty-string types too\n",
    "\n",
    "        years = df[date_col].dt.year.astype(\"Int64\")\n",
    "        grp1 = df.groupby([years, df[type_col]]).size()\n",
    "        for (yr, typ), n in grp1.items():\n",
    "            if pd.isna(yr): continue\n",
    "            agg_year_type[(int(yr), str(typ))] += int(n)\n",
    "\n",
    "        # Optional detailed grouping if division/ward exist\n",
    "        if div_col in df.columns and ward_col in df.columns:\n",
    "            grp2 = df.groupby([years, df[type_col], df[div_col].fillna(\"\"), df[ward_col].fillna(\"\")]).size()\n",
    "            for (yr, typ, dv, wd), n in grp2.items():\n",
    "                if pd.isna(yr): continue\n",
    "                agg_year_type_div_ward[(int(yr), str(typ), str(dv), str(wd))] += int(n)\n",
    "\n",
    "        # Daily totals (for forecasting later)\n",
    "        days = df[date_col].dt.date\n",
    "        grp3 = df.groupby(days).size()\n",
    "        for d, n in grp3.items():\n",
    "            agg_daily[d] += int(n)\n",
    "\n",
    "    counts_y_t = (pd.Series(agg_year_type, name=\"n\")\n",
    "                    .rename_axis([\"year\",\"type\"]).reset_index()\n",
    "                    .sort_values([\"year\",\"n\"], ascending=[True, False]))\n",
    "\n",
    "    if agg_year_type_div_ward:\n",
    "        counts_y_t_d_w = (pd.Series(agg_year_type_div_ward, name=\"n\")\n",
    "                            .rename_axis([\"year\",\"type\",\"division\",\"ward\"]).reset_index()\n",
    "                            .sort_values([\"year\",\"n\"], ascending=[True, False]))\n",
    "    else:\n",
    "        counts_y_t_d_w = pd.DataFrame(columns=[\"year\",\"type\",\"division\",\"ward\",\"n\"])\n",
    "\n",
    "    daily = (pd.Series(agg_daily, name=\"n\")\n",
    "               .rename_axis(\"day\").reset_index()\n",
    "               .sort_values(\"day\"))\n",
    "\n",
    "    return counts_y_t, counts_y_t_d_w, daily\n",
    "\n",
    "# ---- Run on all links and combine ----\n",
    "all_counts, all_counts_detailed, all_daily = [], [], []\n",
    "for u in URLS:\n",
    "    print(\"Reading:\", u)\n",
    "    c1, c2, dly = stream_zip_one(u)\n",
    "    all_counts.append(c1)\n",
    "    if not c2.empty:\n",
    "        all_counts_detailed.append(c2)\n",
    "    all_daily.append(dly)\n",
    "\n",
    "df_counts = (pd.concat(all_counts, ignore_index=True)\n",
    "               .groupby([\"year\",\"type\"], as_index=False)[\"n\"].sum()\n",
    "               .sort_values([\"year\",\"n\"], ascending=[True, False]))\n",
    "\n",
    "daily = (pd.concat(all_daily, ignore_index=True)\n",
    "           .groupby(\"day\", as_index=False)[\"n\"].sum()\n",
    "           .sort_values(\"day\"))\n",
    "\n",
    "if all_counts_detailed:\n",
    "    df_counts_detailed = (pd.concat(all_counts_detailed, ignore_index=True)\n",
    "                            .groupby([\"year\",\"type\",\"division\",\"ward\"], as_index=False)[\"n\"].sum()\n",
    "                            .sort_values([\"year\",\"n\"], ascending=[True, False]))\n",
    "else:\n",
    "    df_counts_detailed = pd.DataFrame(columns=[\"year\",\"type\",\"division\",\"ward\",\"n\"])\n",
    "\n",
    "# Top 15 per year\n",
    "TOP_N = 15\n",
    "top_by_year = (df_counts.groupby(\"year\")\n",
    "               .head(TOP_N)\n",
    "               .reset_index(drop=True))\n",
    "\n",
    "# Save outputs (small tidy files)\n",
    "df_counts.to_csv(DATA_DIR / \"311_counts_year_type_2021_2025.csv\", index=False)\n",
    "top_by_year.to_csv(DATA_DIR / \"311_top_types_by_year_2021_2025.csv\", index=False)\n",
    "daily.to_csv(DATA_DIR / \"311_daily_totals_2021_2025.csv\", index=False)\n",
    "df_counts_detailed.to_csv(DATA_DIR / \"311_counts_year_type_division_ward_2021_2025.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"Wrote:\")\n",
    "print(\" - 311_counts_year_type_2021_2025.csv\")\n",
    "print(\" - 311_top_types_by_year_2021_2025.csv\")\n",
    "print(\" - 311_daily_totals_2021_2025.csv\")\n",
    "print(\" - 311_counts_year_type_division_ward_2021_2025.csv (may be empty if cols absent)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
