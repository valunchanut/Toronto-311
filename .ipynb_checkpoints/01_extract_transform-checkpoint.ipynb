{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f99b7a",
   "metadata": {},
   "source": [
    "# 01 · Extract & Transform — Toronto 311 (Customer-Initiated)\n",
    "Auto-discover yearly resources via CKAN, pull 2021–2025 YTD, clean, and export tidy CSVs.\n",
    "**Defaults:** exclude `Canceled` statuses for demand analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a710694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, re, requests, pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "BASE = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\n",
    "PKG_ID = \"311-service-requests-customer-initiated\"\n",
    "WANT_YEARS = set(range(2021, 2026))  # 2021–2025 inclusive\n",
    "EXPORT_DIR = \"export\"\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "def get_package(pkg_id: str):\n",
    "    res = requests.get(f\"{BASE}/api/3/action/package_show\", params={\"id\": pkg_id})\n",
    "    res.raise_for_status()\n",
    "    j = res.json()\n",
    "    assert j.get(\"success\"), j\n",
    "    return j[\"result\"]\n",
    "\n",
    "def ds_sql(sql: str) -> pd.DataFrame:\n",
    "    res = requests.get(f\"{BASE}/api/3/action/datastore_search_sql\", params={\"sql\": sql})\n",
    "    res.raise_for_status()\n",
    "    j = res.json()\n",
    "    assert j.get(\"success\"), j\n",
    "    return pd.DataFrame(j[\"result\"][\"records\"])\n",
    "\n",
    "def year_counts_datastore(res_id: str) -> pd.DataFrame:\n",
    "    sql = f'''\n",
    "    SELECT\n",
    "      date_part('year', \"Service Request Creation Date and Time\")::int AS year,\n",
    "      \"Original Service Request Type\" AS type,\n",
    "      \"Service Request Division\" AS division,\n",
    "      \"Service Request Ward\" AS ward,\n",
    "      COUNT(*) AS n\n",
    "    FROM \"{res_id}\"\n",
    "    WHERE COALESCE(\"Service Request Status\",'') <> 'Canceled'\n",
    "    GROUP BY 1,2,3,4\n",
    "    '''\n",
    "    return ds_sql(sql)\n",
    "\n",
    "def daily_totals_datastore(res_id: str) -> pd.DataFrame:\n",
    "    sql = f'''\n",
    "    SELECT\n",
    "      date_trunc('day', \"Service Request Creation Date and Time\")::date AS day,\n",
    "      COUNT(*) AS n\n",
    "    FROM \"{res_id}\"\n",
    "    WHERE COALESCE(\"Service Request Status\",'') <> 'Canceled'\n",
    "    GROUP BY 1\n",
    "    ORDER BY 1\n",
    "    '''\n",
    "    return ds_sql(sql)\n",
    "\n",
    "def year_counts_csv(res_url: str) -> pd.DataFrame:\n",
    "    raw = requests.get(res_url).content\n",
    "    df = pd.read_csv(io.BytesIO(raw))\n",
    "    # Normalize columns\n",
    "    ren = {c: c.strip() for c in df.columns}\n",
    "    df = df.rename(columns=ren)\n",
    "    # Parse date\n",
    "    dt = pd.to_datetime(df[\"Service Request Creation Date and Time\"], errors=\"coerce\", utc=True)\n",
    "    df = df.assign(dt=dt).dropna(subset=[\"dt\", \"Original Service Request Type\"])\n",
    "    df = df[df[\"Service Request Status\"].fillna(\"\") != \"Canceled\"]\n",
    "    g = (df.assign(year=df[\"dt\"].dt.year)\n",
    "            .groupby([\"year\",\"Original Service Request Type\",\"Service Request Division\",\"Service Request Ward\"])\n",
    "            .size().reset_index(name=\"n\"))\n",
    "    g.columns = [\"year\",\"type\",\"division\",\"ward\",\"n\"]\n",
    "    return g\n",
    "\n",
    "def daily_totals_csv(res_url: str) -> pd.DataFrame:\n",
    "    raw = requests.get(res_url).content\n",
    "    df = pd.read_csv(io.BytesIO(raw))\n",
    "    ren = {c: c.strip() for c in df.columns}\n",
    "    df = df.rename(columns=ren)\n",
    "    dt = pd.to_datetime(df[\"Service Request Creation Date and Time\"], errors=\"coerce\", utc=True)\n",
    "    df = df.assign(day=dt.dt.date)\n",
    "    df = df[df[\"Service Request Status\"].fillna(\"\") != \"Canceled\"]\n",
    "    g = df.groupby(\"day\").size().reset_index(name=\"n\")\n",
    "    return g\n",
    "\n",
    "# Discover yearly resources\n",
    "pkg = get_package(PKG_ID)\n",
    "YEAR_RX = re.compile(r\"(20\\d{2})\")\n",
    "year_to_res = {}\n",
    "for r in pkg[\"resources\"]:\n",
    "    name = f\"{r.get('name','')} {r.get('description','')}\"\n",
    "    m = YEAR_RX.search(name)\n",
    "    if m:\n",
    "        y = int(m.group(1))\n",
    "        if y in WANT_YEARS:\n",
    "            year_to_res[y] = r\n",
    "\n",
    "print(\"Found years:\", sorted(year_to_res.keys()))\n",
    "\n",
    "# Pull aggregates\n",
    "yearly_frames, daily_frames = [], []\n",
    "for y, r in sorted(year_to_res.items()):\n",
    "    if r.get(\"datastore_active\"):\n",
    "        yearly_frames.append(year_counts_datastore(r[\"id\"]))\n",
    "        daily_frames.append(daily_totals_datastore(r[\"id\"]))\n",
    "    else:\n",
    "        yearly_frames.append(year_counts_csv(r[\"url\"]))\n",
    "        daily_frames.append(daily_totals_csv(r[\"url\"]))\n",
    "\n",
    "df_counts = (pd.concat(yearly_frames, ignore_index=True)\n",
    "               .astype({\"year\": int, \"n\": int})\n",
    "               .sort_values([\"year\",\"n\"], ascending=[True, False]))\n",
    "\n",
    "daily = (pd.concat(daily_frames, ignore_index=True)\n",
    "           .dropna(subset=[\"day\"])\n",
    "           .groupby(\"day\", as_index=False)[\"n\"].sum()\n",
    "           .sort_values(\"day\"))\n",
    "\n",
    "# Top N complaint types per year\n",
    "TOP_N = 15\n",
    "top_by_year = (df_counts.groupby([\"year\",\"type\"], as_index=False)[\"n\"].sum()\n",
    "                        .sort_values([\"year\",\"n\"], ascending=[True, False])\n",
    "                        .groupby(\"year\").head(TOP_N))\n",
    "\n",
    "# Export\n",
    "df_counts.to_csv(os.path.join(EXPORT_DIR, \"311_counts_year_type_division_ward_2021_2025.csv\"), index=False)\n",
    "top_by_year.to_csv(os.path.join(EXPORT_DIR, \"311_top_types_by_year_2021_2025.csv\"), index=False)\n",
    "daily.to_csv(os.path.join(EXPORT_DIR, \"311_daily_totals_2021_2025.csv\"), index=False)\n",
    "\n",
    "print(\"Exports written to:\", EXPORT_DIR)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
